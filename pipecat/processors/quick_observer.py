"""Quick Observer — Layer 1 (0ms) regex-based analysis as a Pipecat FrameProcessor.

Runs synchronously on each TranscriptionFrame before the LLM processes it.
Injects guidance via LLMMessagesAppendFrame for the current response.

Pattern data lives in processors/patterns.py (268 patterns, 19 categories).
This file contains only analysis logic and the FrameProcessor wrapper.
"""

import asyncio
from dataclasses import dataclass, field
from loguru import logger
from pipecat.frames.frames import EndFrame, Frame, TranscriptionFrame, LLMMessagesAppendFrame
from pipecat.processors.frame_processor import FrameProcessor

from processors.patterns import (
    HEALTH_PATTERNS, FAMILY_PATTERNS, EMOTION_PATTERNS, SAFETY_PATTERNS,
    SOCIAL_PATTERNS, ACTIVITY_PATTERNS, TIME_PATTERNS, ENVIRONMENT_PATTERNS,
    ADL_PATTERNS, COGNITIVE_PATTERNS, HELP_REQUEST_PATTERNS, END_OF_LIFE_PATTERNS,
    HYDRATION_PATTERNS, TRANSPORTATION_PATTERNS, NEWS_PATTERNS, GOODBYE_PATTERNS,
    QUESTION_PATTERNS, ENGAGEMENT_PATTERNS, REMINDER_ACK_PATTERNS,
    SAFETY_GUIDANCE, EOL_GUIDANCE, ADL_GUIDANCE, COGNITIVE_GUIDANCE,
    HYDRATION_GUIDANCE, TRANSPORT_GUIDANCE, HEALTH_GUIDANCE, EMOTION_GUIDANCE,
)


# =============================================================================
# Analysis result
# =============================================================================

@dataclass
class AnalysisResult:
    health_signals: list = field(default_factory=list)
    family_signals: list = field(default_factory=list)
    emotion_signals: list = field(default_factory=list)
    safety_signals: list = field(default_factory=list)
    social_signals: list = field(default_factory=list)
    activity_signals: list = field(default_factory=list)
    time_signals: list = field(default_factory=list)
    environment_signals: list = field(default_factory=list)
    adl_signals: list = field(default_factory=list)
    cognitive_signals: list = field(default_factory=list)
    help_request_signals: list = field(default_factory=list)
    end_of_life_signals: list = field(default_factory=list)
    hydration_signals: list = field(default_factory=list)
    transport_signals: list = field(default_factory=list)
    news_signals: list = field(default_factory=list)
    goodbye_signals: list = field(default_factory=list)
    is_question: bool = False
    question_type: str | None = None
    engagement_level: str = "normal"
    guidance: str | None = None
    model_recommendation: dict | None = None
    reminder_response: dict | None = None
    needs_web_search: bool = False


# =============================================================================
# Core analysis function
# =============================================================================

def quick_analyze(user_message: str, recent_history: list[dict] | None = None) -> AnalysisResult:
    """Analyze user message with 268 regex patterns. Returns AnalysisResult with guidance."""
    result = AnalysisResult()
    if not user_message:
        return result

    text = user_message.strip()

    def _scan(patterns, target, *, keyed=False, sev=False, emo=False, strength_key=False):
        for p in patterns:
            if p.pattern.search(text):
                if emo:
                    target.append({"signal": p.signal, "valence": p.valence, "intensity": p.intensity})
                elif sev:
                    target.append({"signal": p.signal, "severity": p.severity})
                elif strength_key:
                    target.append({"signal": p.signal, "strength": p.strength})
                else:
                    target.append(p.signal)

    _scan(HEALTH_PATTERNS, result.health_signals, sev=True)
    _scan(FAMILY_PATTERNS, result.family_signals)
    _scan(EMOTION_PATTERNS, result.emotion_signals, emo=True)
    _scan(SAFETY_PATTERNS, result.safety_signals, sev=True)
    _scan(SOCIAL_PATTERNS, result.social_signals)
    _scan(ACTIVITY_PATTERNS, result.activity_signals)
    _scan(TIME_PATTERNS, result.time_signals)
    _scan(ENVIRONMENT_PATTERNS, result.environment_signals)
    _scan(ADL_PATTERNS, result.adl_signals, sev=True)
    _scan(COGNITIVE_PATTERNS, result.cognitive_signals, sev=True)
    _scan(HELP_REQUEST_PATTERNS, result.help_request_signals)
    _scan(END_OF_LIFE_PATTERNS, result.end_of_life_signals, sev=True)
    _scan(HYDRATION_PATTERNS, result.hydration_signals, sev=True)
    _scan(TRANSPORTATION_PATTERNS, result.transport_signals, sev=True)

    # News — also sets needs_web_search
    for p in NEWS_PATTERNS:
        if p.pattern.search(text):
            result.news_signals.append(p.signal)
            result.needs_web_search = True

    _scan(GOODBYE_PATTERNS, result.goodbye_signals, strength_key=True)

    # Questions
    for p in QUESTION_PATTERNS:
        if p.pattern.search(text):
            result.is_question = True
            result.question_type = p.signal
            break

    # Engagement
    for p in ENGAGEMENT_PATTERNS:
        if p.pattern.search(text):
            if p.signal in ("minimal_response", "very_short", "uncertain_response"):
                result.engagement_level = "low"
            elif p.signal == "short" and result.engagement_level != "low":
                result.engagement_level = "medium"
            elif p.signal == "long_response":
                result.engagement_level = "high"

    # Consecutive short responses → low engagement
    if recent_history and len(recent_history) >= 2:
        user_msgs = [m["content"] for m in recent_history if m.get("role") == "user"][-3:]
        if sum(1 for m in user_msgs if m and len(m) < 20) >= 2:
            result.engagement_level = "low"

    # Reminder acknowledgment
    best = None
    for p in REMINDER_ACK_PATTERNS:
        if p.pattern.search(text):
            if best is None or p.confidence > best["confidence"]:
                best = {"type": p.type, "confidence": p.confidence}
    result.reminder_response = best

    result.guidance = _build_guidance(result)
    result.model_recommendation = _build_model_recommendation(result)
    return result


# =============================================================================
# Guidance builder
# =============================================================================

def _build_guidance(r: AnalysisResult) -> str | None:
    lines: list[str] = []

    if r.safety_signals:
        sig = r.safety_signals[0]["signal"]
        lines.append(f"[SAFETY] {SAFETY_GUIDANCE.get(sig, 'Safety concern detected. Ask if they are okay.')}")

    if r.end_of_life_signals:
        sig = r.end_of_life_signals[0]["signal"]
        lines.append(f"[END OF LIFE] {EOL_GUIDANCE.get(sig, 'Sensitive topic. Be very gentle and listen.')}")

    if r.adl_signals:
        sig = r.adl_signals[0]["signal"]
        lines.append(f"[DAILY LIVING] {ADL_GUIDANCE.get(sig, 'They mentioned difficulty with daily tasks. Ask how they are managing.')}")

    if r.cognitive_signals:
        sig = r.cognitive_signals[0]["signal"]
        lines.append(f"[COGNITIVE] {COGNITIVE_GUIDANCE.get(sig, 'Possible cognitive concern. Be patient and reassuring.')}")

    if r.hydration_signals:
        sig = r.hydration_signals[0]["signal"]
        lines.append(f"[NUTRITION] {HYDRATION_GUIDANCE.get(sig, 'Nutrition concern. Ask about their eating and drinking.')}")

    if r.transport_signals:
        sig = r.transport_signals[0]["signal"]
        lines.append(f"[TRANSPORT] {TRANSPORT_GUIDANCE.get(sig, 'Transportation came up. Ask how they are getting around.')}")

    if r.help_request_signals:
        lines.append("[HELP REQUEST] They're asking for help. Address their request directly and clearly.")

    if r.health_signals:
        sig = r.health_signals[0]["signal"]
        lines.append(f"[HEALTH] {HEALTH_GUIDANCE.get(sig, 'Health topic mentioned. Ask how they are feeling.')}")

    neg = [e for e in r.emotion_signals if e["valence"] == "negative"]
    pos = [e for e in r.emotion_signals if e["valence"] == "positive"]
    if neg:
        sig = neg[0]["signal"]
        lines.append(f"[EMOTION] {EMOTION_GUIDANCE.get(sig, 'They seem upset. Acknowledge their feelings.')}")
    elif pos:
        if pos[0]["intensity"] == "high":
            lines.append("[EMOTION] They're in great spirits! Match their positive energy.")
        else:
            lines.append("[EMOTION] They seem positive. Keep the warm tone.")

    if "social_isolation" in r.social_signals:
        lines.append("[SOCIAL] They haven't seen anyone lately. Be extra warm and engaging.")
    elif r.social_signals:
        lines.append("[SOCIAL] Social connection mentioned. Ask warm follow-up questions.")

    if r.family_signals:
        if "deceased_spouse" in r.family_signals:
            lines.append("[FAMILY] They mentioned late spouse. Be gentle and let them share if they want.")
        else:
            lines.append("[FAMILY] Family mentioned. Ask a warm follow-up about this person.")

    if r.activity_signals:
        lines.append("[ACTIVITY] They mentioned an activity. Ask more about it with genuine interest.")

    if any(s in r.time_signals for s in ("reminiscing", "childhood_memory", "nostalgia")):
        lines.append("[MEMORY] They're sharing memories. Listen warmly and ask follow-up questions.")

    if r.is_question:
        lines.append("[QUESTION] Answer their question directly first, then continue naturally.")

    if r.engagement_level == "low":
        lines.append("[ENGAGEMENT] Short responses detected. Ask an open question about something they enjoy.")

    if r.goodbye_signals:
        has_strong = any(g["strength"] == "strong" for g in r.goodbye_signals)
        if has_strong:
            lines.append("[GOODBYE] They said goodbye. Say a brief warm goodbye and then CALL transition_to_winding_down immediately. You MUST use the tool — do not just say bye in text.")
        else:
            lines.append("[GOODBYE] They may be wrapping up. Start winding down and prepare to call transition_to_winding_down.")

    return "\n".join(lines) if lines else None


# =============================================================================
# Model recommendation — 16 priority-ordered token rules
# =============================================================================

def _build_model_recommendation(r: AnalysisResult) -> dict | None:
    # End of life critical
    crit_eol = [s for s in r.end_of_life_signals if s["signal"] in ("death_wish", "hopelessness", "burden_concern")]
    if crit_eol:
        return {"use_sonnet": True, "max_tokens": 350, "reason": "crisis_support"}

    if any(s["severity"] == "high" for s in r.safety_signals):
        return {"use_sonnet": True, "max_tokens": 300, "reason": "safety_concern"}

    if any(s["severity"] == "high" for s in r.adl_signals):
        return {"use_sonnet": True, "max_tokens": 250, "reason": "functional_concern"}

    if any(s["severity"] == "high" for s in r.cognitive_signals):
        return {"use_sonnet": True, "max_tokens": 250, "reason": "cognitive_concern"}

    if any(s["severity"] == "high" for s in r.hydration_signals):
        return {"use_sonnet": True, "max_tokens": 220, "reason": "nutrition_concern"}

    if any(s["severity"] == "high" for s in r.health_signals):
        return {"use_sonnet": True, "max_tokens": 250, "reason": "health_safety"}

    if any(s["severity"] == "medium" for s in r.health_signals):
        return {"use_sonnet": True, "max_tokens": 200, "reason": "health_mention"}

    if r.end_of_life_signals:
        return {"use_sonnet": True, "max_tokens": 250, "reason": "end_of_life_topic"}

    if any(s["severity"] == "medium" for s in r.adl_signals):
        return {"use_sonnet": True, "max_tokens": 200, "reason": "functional_mention"}

    if any(s["severity"] == "medium" for s in r.cognitive_signals):
        return {"use_sonnet": True, "max_tokens": 200, "reason": "cognitive_mention"}

    if any(s["severity"] == "high" for s in r.transport_signals):
        return {"use_sonnet": True, "max_tokens": 200, "reason": "mobility_isolation"}

    if r.help_request_signals:
        return {"use_sonnet": True, "max_tokens": 200, "reason": "help_request"}

    high_neg = [e for e in r.emotion_signals if e["valence"] == "negative" and e["intensity"] == "high"]
    if high_neg:
        return {"use_sonnet": True, "max_tokens": 250, "reason": "emotional_support"}

    med_neg = [e for e in r.emotion_signals if e["valence"] == "negative" and e["intensity"] == "medium"]
    if med_neg:
        return {"use_sonnet": True, "max_tokens": 200, "reason": "emotional_support"}

    if r.engagement_level == "low":
        return {"use_sonnet": True, "max_tokens": 180, "reason": "low_engagement"}

    if any(s in r.time_signals for s in ("reminiscing", "childhood_memory")):
        return {"use_sonnet": False, "max_tokens": 170, "reason": "memory_sharing"}

    if r.engagement_level == "high":
        return {"use_sonnet": False, "max_tokens": 150, "reason": "high_engagement"}

    if r.is_question and not r.health_signals and not high_neg:
        return {"use_sonnet": False, "max_tokens": 100, "reason": "simple_question"}

    if r.family_signals:
        return {"use_sonnet": False, "max_tokens": 150, "reason": "family_warmth"}

    return None


# =============================================================================
# Pipecat FrameProcessor wrapper
# =============================================================================

class QuickObserverProcessor(FrameProcessor):
    """Pipecat FrameProcessor that runs quick_analyze on each TranscriptionFrame
    and injects guidance into the LLM context via LLMMessagesAppendFrame.

    When a strong goodbye is detected, schedules a forced call end after a delay
    to ensure the call actually terminates (LLM tool calls are unreliable for this).
    """

    # Seconds to wait after goodbye detection before forcing call end.
    # Gives the LLM time to generate and TTS to speak the goodbye audio.
    GOODBYE_DELAY_SECONDS = 2.0

    def __init__(self, session_state: dict | None = None, **kwargs):
        super().__init__(**kwargs)
        self._recent_history: list[dict] = []
        self.last_analysis: AnalysisResult | None = None
        self._session_state = session_state
        self._pipeline_task = None  # Set via set_pipeline_task() after pipeline creation
        self._goodbye_task: asyncio.Task | None = None

    def set_pipeline_task(self, task):
        """Set the pipeline task reference for programmatic call ending."""
        self._pipeline_task = task

    async def _force_end_call(self):
        """Wait for goodbye audio to play, then end the call via EndFrame."""
        try:
            await asyncio.sleep(self.GOODBYE_DELAY_SECONDS)
            if self._pipeline_task:
                logger.info("[QuickObserver] Goodbye timeout reached — ending call programmatically")
                await self._pipeline_task.queue_frame(EndFrame())
            else:
                logger.warning("[QuickObserver] No pipeline_task set — cannot force end call")
        except asyncio.CancelledError:
            logger.info("[QuickObserver] Goodbye end-call timer cancelled")
        except Exception as e:
            logger.error("[QuickObserver] Error forcing call end: {err}", err=str(e))

    async def process_frame(self, frame: Frame, direction):
        await super().process_frame(frame, direction)

        if isinstance(frame, TranscriptionFrame):
            text = frame.text
            analysis = quick_analyze(text, self._recent_history)
            self.last_analysis = analysis

            # Track recent history for engagement detection
            self._recent_history.append({"role": "user", "content": text})
            if len(self._recent_history) > 10:
                self._recent_history = self._recent_history[-10:]

            # Inject guidance into LLM context if there is any.
            # Use "user" role — Anthropic rejects "system" in the messages array.
            if analysis.guidance:
                guidance_msg = {
                    "role": "user",
                    "content": f"[Internal guidance — do not read aloud]\n{analysis.guidance}",
                }
                await self.push_frame(
                    LLMMessagesAppendFrame(messages=[guidance_msg], run_llm=False)
                )

            # PROGRAMMATIC GOODBYE: When strong goodbye detected, schedule forced
            # call end. The LLM will still generate its goodbye response normally,
            # but we don't rely on it to call the transition tools.
            if analysis.goodbye_signals and self._goodbye_task is None:
                has_strong = any(g["strength"] == "strong" for g in analysis.goodbye_signals)
                if has_strong:
                    logger.info(
                        "[QuickObserver] Strong goodbye detected — scheduling forced end in {d}s",
                        d=self.GOODBYE_DELAY_SECONDS,
                    )
                    self._goodbye_task = asyncio.create_task(self._force_end_call())
                    # Signal to Director to suppress stale guidance
                    if self._session_state is not None:
                        self._session_state["_goodbye_in_progress"] = True

            # Cancel goodbye timer if senior keeps speaking (false goodbye)
            elif self._goodbye_task is not None and not self._goodbye_task.done():
                if not analysis.goodbye_signals:
                    logger.info("[QuickObserver] Senior still speaking — cancelling goodbye timer")
                    self._goodbye_task.cancel()
                    self._goodbye_task = None
                    if self._session_state is not None:
                        self._session_state["_goodbye_in_progress"] = False

        # Always pass frames through
        await self.push_frame(frame, direction)
